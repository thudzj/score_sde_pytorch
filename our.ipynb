{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa9OIcJmUKmZ",
        "outputId": "8fde468b-2c95-4003-f0bd-20ddad5248e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-18 21:10:11.036232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/zhijie/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# #@title Autoload all modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import importlib\n",
        "import os\n",
        "import functools\n",
        "import itertools\n",
        "import torch\n",
        "from losses import get_optimizer\n",
        "from models.ema import ExponentialMovingAverage\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "import tqdm\n",
        "import io\n",
        "import likelihood\n",
        "import controllable_generation\n",
        "from utils import restore_checkpoint\n",
        "sns.set(font_scale=2)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "import models\n",
        "from models import utils as mutils\n",
        "from models import ncsnv2\n",
        "from models import ncsnpp\n",
        "from models import ddpm as ddpm_model\n",
        "from models import layerspp\n",
        "from models import layers\n",
        "from models import normalization\n",
        "import sampling\n",
        "from likelihood import get_likelihood_fn\n",
        "from sde_lib import VESDE, VPSDE, subVPSDE\n",
        "from sampling import (ReverseDiffusionPredictor, \n",
        "                      LangevinCorrector, \n",
        "                      EulerMaruyamaPredictor, \n",
        "                      AncestralSamplingPredictor, \n",
        "                      NoneCorrector, \n",
        "                      NonePredictor,\n",
        "                      AnnealedLangevinDynamics)\n",
        "import datasets\n",
        "import wrapper\n",
        "from fid_utils import get_fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "-reedYgCU79v"
      },
      "outputs": [],
      "source": [
        "# @title Load the score-based model\n",
        "sde = 'VESDE' #@param ['VESDE', 'VPSDE', 'subVPSDE'] {\"type\": \"string\"}\n",
        "if sde.lower() == 'vesde':\n",
        "  from configs.ve import cifar10_ncsnpp_continuous as configs\n",
        "  ckpt_filename = \"exp/ve/cifar10_ncsnpp_continuous/checkpoint_24.pth\"\n",
        "  config = configs.get_config()  \n",
        "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-5\n",
        "elif sde.lower() == 'vpsde':\n",
        "  from configs.vp import cifar10_ddpmpp_continuous as configs  \n",
        "  ckpt_filename = \"exp/vp/cifar10_ddpmpp_continuous/checkpoint_8.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "elif sde.lower() == 'subvpsde':\n",
        "  from configs.subvp import cifar10_ddpmpp_continuous as configs\n",
        "  ckpt_filename = \"exp/subvp/cifar10_ddpmpp_continuous/checkpoint_26.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "\n",
        "batch_size =   64#@param {\"type\":\"integer\"}\n",
        "config.training.batch_size = batch_size\n",
        "config.eval.batch_size = batch_size\n",
        "\n",
        "random_seed = 0 #@param {\"type\": \"integer\"}\n",
        "\n",
        "sigmas = mutils.get_sigmas(config)\n",
        "scaler = datasets.get_data_scaler(config)\n",
        "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
        "score_model = mutils.create_model(config)\n",
        "\n",
        "optimizer = get_optimizer(config, score_model.parameters())\n",
        "ema = ExponentialMovingAverage(score_model.parameters(),\n",
        "                               decay=config.model.ema_rate)\n",
        "state = dict(step=0, optimizer=optimizer,\n",
        "             model=score_model, ema=ema)\n",
        "\n",
        "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
        "ema.copy_to(score_model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "G8ei2Xsfg6JQ"
      },
      "outputs": [],
      "source": [
        "#@title Visualization code\n",
        "\n",
        "def image_grid(x):\n",
        "  size = config.data.image_size\n",
        "  channels = config.data.num_channels\n",
        "  img = x.reshape(-1, size, size, channels)\n",
        "  w = int(np.sqrt(img.shape[0]))\n",
        "  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
        "  return img\n",
        "\n",
        "def show_samples(x):\n",
        "  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "  img = image_grid(x)\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-18 21:11:34.564823: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-10-18 21:11:34.565050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-10-18 21:11:34.567121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2022-10-18 21:11:34.568755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
            "pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2022-10-18 21:11:34.568818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-10-18 21:11:34.572535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-10-18 21:11:34.572593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-10-18 21:11:34.574050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-10-18 21:11:34.574272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-10-18 21:11:34.575717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-10-18 21:11:34.576377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-10-18 21:11:34.576535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-10-18 21:11:34.589648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
            "2022-10-18 21:11:34.607044: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-10-18 21:11:34.753910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2022-10-18 21:11:34.755494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
            "pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2022-10-18 21:11:34.755554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-10-18 21:11:34.755580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-10-18 21:11:34.755593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-10-18 21:11:34.755606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-10-18 21:11:34.755618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-10-18 21:11:34.755630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-10-18 21:11:34.755642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-10-18 21:11:34.755655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-10-18 21:11:34.763417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
            "2022-10-18 21:11:34.763718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-10-18 21:11:38.442667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-10-18 21:11:38.442772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
            "2022-10-18 21:11:38.442780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
            "2022-10-18 21:11:38.442784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
            "2022-10-18 21:11:38.449947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 19198 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
            "2022-10-18 21:11:38.453383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 21100 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:25:00.0, compute capability: 8.6)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of all generations: 50000 eval_batch_size: 64\n",
            "sampling -- round: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zhijie/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
            "/home/zhijie/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2273: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/home/zhijie/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1402: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`layer.updates` will be removed in a future version. '\n",
            "2022-10-18 21:14:45.564794: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-10-18 21:14:45.617105: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n",
            "2022-10-18 21:14:46.594582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-10-18 21:14:47.284792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-10-18 21:14:47.291098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-10-18 21:14:47.356700: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
            "2022-10-18 21:14:47.368810: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
            "2022-10-18 21:14:47.368945: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n"
          ]
        },
        {
          "ename": "UnknownError",
          "evalue": "3 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PartitionedCall_1/PartitionedCall/PartitionedCall/inception/conv}}]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PartitionedCall_1/PartitionedCall/PartitionedCall/inception/conv}}]]\n\t [[PartitionedCall_1/PartitionedCall/PartitionedCall/inception/MatMul/_8]]\n  (2) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PartitionedCall_1/PartitionedCall/PartitionedCall/inception/conv}}]]\n\t [[split/_2]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_run_inception_distributed_1645]\n\nFunction call stack:\nrun_inception_distributed -> run_inception_distributed -> run_inception_distributed\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_3094825/4294109129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# x, n = sampling_fn(score_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# show_samples(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mget_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'assets/stats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_filename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/score_sde_pytorch/fid_utils.py\u001b[0m in \u001b[0;36mget_fid\u001b[0;34m(config, sampling_fn, score_model, eval_dir, job_name)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         latents = evaluation.run_inception_distributed(samples, inception_model,\n\u001b[0;32m---> 38\u001b[0;31m                                                        inceptionv3=inceptionv3)\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Force garbage collection again before returning to JAX code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/anaconda3/envs/env37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: 3 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PartitionedCall_1/PartitionedCall/PartitionedCall/inception/conv}}]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PartitionedCall_1/PartitionedCall/PartitionedCall/inception/conv}}]]\n\t [[PartitionedCall_1/PartitionedCall/PartitionedCall/inception/MatMul/_8]]\n  (2) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PartitionedCall_1/PartitionedCall/PartitionedCall/inception/conv}}]]\n\t [[split/_2]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_run_inception_distributed_1645]\n\nFunction call stack:\nrun_inception_distributed -> run_inception_distributed -> run_inception_distributed\n"
          ]
        }
      ],
      "source": [
        "#@title PC sampling\n",
        "img_size = config.data.image_size\n",
        "channels = config.data.num_channels\n",
        "shape = (batch_size, channels, img_size, img_size)\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps =  1#@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
        "                                      inverse_scaler, snr, n_steps=n_steps,\n",
        "                                      probability_flow=probability_flow,\n",
        "                                      continuous=config.training.continuous,\n",
        "                                      eps=sampling_eps, device=config.device)\n",
        "# x, n = sampling_fn(score_model)\n",
        "# show_samples(x)\n",
        "config.eval.batch_size = 32\n",
        "get_fid(config, sampling_fn, score_model, eval_dir='assets/stats', job_name='_'.join(ckpt_filename.split('/')[:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'shape' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_3094825/2503165592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                       \u001b[0minverse_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       \u001b[0mprobability_flow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobability_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
          ]
        }
      ],
      "source": [
        "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
        "                                      inverse_scaler, snr, n_steps=n_steps,\n",
        "                                      probability_flow=probability_flow,\n",
        "                                      continuous=config.training.continuous,\n",
        "                                      eps=sampling_eps, device=config.device, \n",
        "                                      use_wrapper=True,\n",
        "                                      calibration=False,\n",
        "                                      score_mean='mean_scores/exp_ve_cifar10_ncsnpp_continuous_checkpoint_24.pth')\n",
        "\n",
        "# x, n = sampling_fn(score_model)\n",
        "# show_samples(x)\n",
        "get_fid(config, sampling_fn, score_model, eval_dir='assets/stats', job_name='our')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the momentum of estimated scores\n",
        "\n",
        "score_fn = mutils.get_score_fn(sde, score_model, train=False, continuous=config.training.continuous)\n",
        "n_estimates = 1\n",
        "config.eval.batch_size = 1024\n",
        "\n",
        "# Build data iterators\n",
        "train_ds, _, _ = datasets.get_dataset(config,\n",
        "                                      uniform_dequantization=config.data.uniform_dequantization,\n",
        "                                      evaluation=True)\n",
        "train_iter = iter(train_ds)\n",
        "\n",
        "with torch.no_grad():\n",
        "    timesteps = torch.linspace(sde.T, sampling_eps, sde.N, device=config.device)\n",
        "\n",
        "    score_sum = torch.zeros(sde.N, channels, img_size, img_size).to(config.device)\n",
        "    score_normsqr_sum = torch.zeros(sde.N).to(config.device)\n",
        "    n_data = 0\n",
        "    \n",
        "    while 1:\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except StopIteration:\n",
        "            break\n",
        "        x = torch.from_numpy(batch['image']._numpy()).to(config.device).float()\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = scaler(x)\n",
        "\n",
        "        for i in range(sde.N):\n",
        "            t = timesteps[i]\n",
        "            vec_t = torch.ones(x.shape[0], device=t.device) * t \n",
        "            mean, std = sde.marginal_prob(x, vec_t)\n",
        "            \n",
        "            for _ in range(n_estimates):\n",
        "                perturbed_data = mean + std[:, None, None, None] * torch.randn_like(x)\n",
        "                score = score_fn(perturbed_data, vec_t)\n",
        "                score_sum[i] += score.sum(0)\n",
        "                score_normsqr_sum[i] += (score.flatten(1).norm(dim=1) ** 2).sum(0)\n",
        "        \n",
        "        n_data += n_estimates * x.shape[0]\n",
        "        print(n_data / n_estimates)\n",
        "\n",
        "        score_mean = score_sum / n_data\n",
        "        score_mean_normsqr = score_mean.flatten(1).norm(dim=1) ** 2\n",
        "        score_normsqr_mean = score_normsqr_sum / n_data\n",
        "        ratio = (score_mean_normsqr / score_normsqr_mean).sqrt()\n",
        "        torch.save(score_mean.cpu(), \"mean_scores/{}_\".format(n_data // n_estimates) + ckpt_filename.replace(\"/\", \"_\"))\n",
        "\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
        "        ax1.plot(range(sde.N), score_normsqr_mean.cpu().numpy())\n",
        "        ax2.plot(range(sde.N), score_mean_normsqr.cpu().numpy())\n",
        "        ax3.plot(range(sde.N), ratio.cpu().numpy())\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### a baseline\n",
        "batch_size = 64\n",
        "img_size = config.data.image_size\n",
        "channels = config.data.num_channels\n",
        "shape = (batch_size, channels, img_size, img_size)\n",
        "probability_flow = False\n",
        "\n",
        "score_fn = mutils.get_score_fn(sde, score_model, train=False, continuous=config.training.continuous)\n",
        "rsde = sde.reverse(score_fn, probability_flow)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Initial sample\n",
        "    x = sde.prior_sampling(shape).to(config.device)\n",
        "    timesteps = torch.linspace(sde.T, sampling_eps, sde.N, device=config.device)\n",
        "\n",
        "    for i in range(sde.N):\n",
        "        t = timesteps[i]\n",
        "        vec_t = torch.ones(shape[0], device=t.device) * t\n",
        "\n",
        "        f, G = rsde.discretize(x, vec_t)\n",
        "        z = torch.randn_like(x)\n",
        "        x_mean = x - f\n",
        "        x = x_mean + G[:, None, None, None] * z\n",
        "\n",
        "    x = inverse_scaler(x_mean)\n",
        "    \n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "timesteps = torch.linspace(sde.T, sampling_eps, sde.N, device=config.device)\n",
        "new_score_fn = wrapper.score_fn_wrapper(sde, score_fn, config.training.continuous, score_mean='mean_scores/exp_ve_cifar10_ncsnpp_continuous_checkpoint_24.pth', device=timesteps.device)\n",
        "new_score_fn = partial(new_score_fn, timesteps=timesteps)\n",
        "rsde = sde.reverse(new_score_fn, probability_flow)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Initial sample\n",
        "    x = sde.prior_sampling(shape).to(config.device)\n",
        "    \n",
        "    for i in range(sde.N):\n",
        "        t = timesteps[i]\n",
        "        vec_t = torch.ones(shape[0], device=t.device) * t\n",
        "\n",
        "        f, G = rsde.discretize(x, vec_t)\n",
        "        z = torch.randn_like(x)\n",
        "        x_mean = x - f\n",
        "        x = x_mean + G[:, None, None, None] * z\n",
        "\n",
        "    x = inverse_scaler(x_mean)\n",
        "    \n",
        "show_samples(x)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Score SDE demo PyTorch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "vscode": {
      "interpreter": {
        "hash": "41bc226e2d9f836d9859763e87d3868b21f72153d4ccdcc0578cadb230ab8cea"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
